"""
Artwork Analysis System with Metadata Recognition & Similar Art Search
Components: Style Classification, Artist Recognition, Metadata API Integration, Similarity Search
"""

import os
import requests
import numpy as np
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import cv2
import json
from sklearn.neighbors import NearestNeighbors
from typing import Tuple, Dict, List

# ========================
# Configuration
# ========================
class Config:
    GOOGLE_API_KEY = "YOUR_GOOGLE_API_KEY"
    WIKIDATA_API = "https://www.wikidata.org/w/api.php"
    METMUSEUM_API = "https://collectionapi.metmuseum.org/public/collection/v1"
    IMG_SIZE = 512
    MODEL_PATH = "art_classifier_advanced.pth"
    METADATA_DB = "art_metadata.json"
    FEATURE_DB = "art_features.npy"
    SIMILARITY_THRESHOLD = 0.85
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ========================
# Enhanced Model Architecture
# ========================
class ArtAnalysisModel(nn.Module):
    def __init__(self, num_styles: int = 20, num_artists: int = 100):
        super().__init__()
        base = torchvision.models.resnet50(pretrained=True)
        self.feature_extractor = nn.Sequential(*list(base.children())[:-1])
        self.style_classifier = nn.Sequential(
            nn.Linear(2048, 512),
            nn.ReLU(),
            nn.Linear(512, num_styles)
        )
        self.artist_classifier = nn.Sequential(
            nn.Linear(2048, 512),
            nn.ReLU(),
            nn.Linear(512, num_artists)
        )
        
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        features = self.feature_extractor(x).flatten(1)
        return features, self.style_classifier(features), self.artist_classifier(features)

# ========================
# Metadata Database Manager
# ========================
class ArtMetadataDB:
    def __init__(self):
        self.metadata = self._load_metadata()
        self.feature_vectors = np.load(Config.FEATURE_DB) if os.path.exists(Config.FEATURE_DB) else None
        self.knn = NearestNeighbors(n_neighbors=5, metric="cosine") if self.feature_vectors is not None else None
        
    def _load_metadata(self) -> Dict:
        if os.path.exists(Config.METADATA_DB):
            with open(Config.METADATA_DB, "r") as f:
                return json.load(f)
        return {}
    
    def add_entry(self, artwork_id: str, features: np.ndarray, metadata: Dict):
        self.metadata[artwork_id] = metadata
        if self.feature_vectors is None:
            self.feature_vectors = features[np.newaxis, :]
        else:
            self.feature_vectors = np.vstack([self.feature_vectors, features])
        self._save_data()
        
    def find_similar(self, query_features: np.ndarray) -> List[Dict]:
        if self.knn is None:
            self.knn = NearestNeighbors(n_neighbors=5, metric="cosine").fit(self.feature_vectors)
        distances, indices = self.knn.kneighbors(query_features)
        return [self.metadata[list(self.metadata.keys())[idx]] for idx in indices[0]]

    def _save_data(self):
        np.save(Config.FEATURE_DB, self.feature_vectors)
        with open(Config.METADATA_DB, "w") as f:
            json.dump(self.metadata, f)

# ========================
# API Integrations
# ========================
class ArtworkAPI:
    @staticmethod
    def get_wikidata_info(search_term: str) -> Dict:
        params = {
            "action": "wbsearchentities",
            "format": "json",
            "language": "en",
            "search": search_term
        }
        response = requests.get(Config.WIKIDATA_API, params=params)
        return response.json().get("search", [{}])[0]

    @staticmethod
    def get_metmuseum_info(object_id: str) -> Dict:
        response = requests.get(f"{Config.METMUSEUM_API}/objects/{object_id}")
        return response.json()

    @staticmethod
    def reverse_image_search(image_path: str) -> Dict:
        search_url = "https://serpapi.com/search"
        params = {
            "engine": "google_lens",
            "url": image_path,
            "api_key": Config.GOOGLE_API_KEY
        }
        response = requests.get(search_url, params=params)
        return response.json().get("visual_matches", [])

# ========================
# Image Processing Pipeline
# ========================
class ArtProcessor:
    def __init__(self):
        self.transform = transforms.Compose([
            transforms.Resize((Config.IMG_SIZE, Config.IMG_SIZE)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
    def process_image(self, image_path: str) -> torch.Tensor:
        image = Image.open(image_path).convert("RGB")
        return self.transform(image).unsqueeze(0).to(Config.DEVICE)

# ========================
# Main Analysis System
# ========================
class ArtAnalyzer:
    def __init__(self):
        self.model = ArtAnalysisModel().to(Config.DEVICE)
        self.model.load_state_dict(torch.load(Config.MODEL_PATH))
        self.metadata_db = ArtMetadataDB()
        self.processor = ArtProcessor()
        
    def analyze_artwork(self, image_path: str) -> Dict:
        # Process image
        tensor_image = self.processor.process_image(image_path)
        
        # Get model predictions
        with torch.no_grad():
            features, style_pred, artist_pred = self.model(tensor_image)
        
        # Get basic metadata from reverse image search
        reverse_search = ArtworkAPI.reverse_image_search(image_path)
        metadata = self._parse_reverse_search(reverse_search)
        
        # Get detailed metadata from APIs
        if metadata.get("title"):
            wikidata = ArtworkAPI.get_wikidata_info(metadata["title"])
            metadata.update(self._parse_wikidata(wikidata))
        
        # Find similar artworks
        similar = self.metadata_db.find_similar(features.cpu().numpy())
        
        return {
            **metadata,
            "style": self._get_style_name(style_pred.argmax().item()),
            "artist_confidence": torch.softmax(artist_pred, dim=1).max().item(),
            "similar_artworks": similar
        }
    
    def _parse_reverse_search(self, search_results: List) -> Dict:
        if not search_results:
            return {}
        best_match = search_results[0]
        return {
            "title": best_match.get("title"),
            "artist": best_match.get("source").get("name") if best_match.get("source") else None,
            "year": best_match.get("year"),
            "source": "Google Lens"
        }
    
    def _parse_wikidata(self, wikidata: Dict) -> Dict:
        return {
            "description": wikidata.get("description"),
            "wikidata_id": wikidata.get("id"),
            "detailed_date": wikidata.get("dates"),
            "movement": wikidata.get("movement")
        }
    
    def _get_style_name(self, style_idx: int) -> str:
        # Replace with actual style labels
        styles = ["Abstract", "Renaissance", "Impressionism", "Cubism", "Surrealism"]
        return styles[style_idx] if style_idx < len(styles) else "Unknown"

# ========================
# Usage Example
# ========================
if __name__ == "__main__":
    analyzer = ArtAnalyzer()
    
    # Analyze new artwork
    result = analyzer.analyze_artwork("user_photo.jpg")
    
    print("\nArtwork Analysis Report:")
    print(f"Title: {result.get('title', 'Unknown')}")
    print(f"Artist: {result.get('artist', 'Unknown')}")
    print(f"Creation Date: {result.get('year', 'Unknown')}")
    print(f"Style/Movement: {result['style']}")
    print(f"Artist Confidence: {result['artist_confidence']:.2%}")
    
    print("\nSimilar Artworks:")
    for idx, art in enumerate(result["similar_artworks"], 1):
        print(f"{idx}. {art.get('title')} by {art.get('artist')} ({art.get('year')})")
